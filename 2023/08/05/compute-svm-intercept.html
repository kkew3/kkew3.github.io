<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>How to compute the intercept of C-SVM in primal and dual formulations | Kaiwen’s personal website</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="How to compute the intercept of C-SVM in primal and dual formulations">
<meta property="og:locale" content="en_US">
<meta name="description" content="Compute intercept in primal formulation">
<meta property="og:description" content="Compute intercept in primal formulation">
<link rel="canonical" href="https://kkew3.github.io/2023/08/05/compute-svm-intercept.html">
<meta property="og:url" content="https://kkew3.github.io/2023/08/05/compute-svm-intercept.html">
<meta property="og:site_name" content="Kaiwen’s personal website">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-08-05T08:08:26+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="How to compute the intercept of C-SVM in primal and dual formulations">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-08-05T08:08:26+00:00","datePublished":"2023-08-05T08:08:26+00:00","description":"Compute intercept in primal formulation","headline":"How to compute the intercept of C-SVM in primal and dual formulations","mainEntityOfPage":{"@type":"WebPage","@id":"https://kkew3.github.io/2023/08/05/compute-svm-intercept.html"},"url":"https://kkew3.github.io/2023/08/05/compute-svm-intercept.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
<link type="application/atom+xml" rel="alternate" href="https://kkew3.github.io/feed.xml" title="Kaiwen's personal website">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2YQN8LEHLR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2YQN8LEHLR');
</script>
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header class="site-header" role="banner">

  <div class="wrapper">
<a class="site-title" rel="author" href="/">Kaiwen's personal website</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
<a class="page-link" href="/tags/">Tags</a><a class="page-link" href="/docs/">Docs</a><a class="page-link" href="/about/">About</a>
</div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to compute the intercept of C-SVM in primal and dual formulations</h1>
    <span><a href="https://kkew3.github.io/tags/ml--svm"><code class="highlighter-rouge"><nobr>machine learning/svm</nobr></code></a></span>
    <p class="post-meta">
      <time class="dt-published" datetime="2023-08-05T08:08:26+00:00" itemprop="datePublished">Aug 5, 2023 at 08:08:26
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="compute-intercept-in-primal-formulation">Compute intercept in primal formulation</h2>

<p>The primal SVM problem is:</p>

\[\min_{\boldsymbol w,b,\boldsymbol\xi} \frac{1}{2}\boldsymbol w^\top\boldsymbol w+C\sum_{i=1}^m\xi_i;\quad\text{s.t. }\ y_i f(\boldsymbol x_i) \ge 1-\xi_i,\ \xi_i \ge 0 \,,\tag{1}\]

<p>where the decision function $f(\boldsymbol x) \equiv \boldsymbol w^\top\phi(\boldsymbol x) + b$.
The Lagrangian is:</p>

\[L(\boldsymbol w,b,\boldsymbol\xi,\boldsymbol\alpha,\boldsymbol\mu) = \frac{1}{2}\boldsymbol w^\top\boldsymbol w + C\sum_{i=1}^m\xi_i + \sum_{i=1}^m\alpha_i\big(1-\xi_i-y_i f(\boldsymbol x_i)\big) - \sum_{i=1}^m\mu_i\xi_i\,,\]

<p>where $\alpha_i \ge 0$, $\mu_i \ge 0$.
The Karush-Kuhn-Tucker (KKT) conditions are:</p>

\[\begin{cases}
\boldsymbol w=\sum_{i=1}^m\alpha_i y_i \phi(\boldsymbol x_i) &amp;\text{(stationarity)}\\
0=\sum_{i=1}^m\alpha_i y_i &amp;\text{(stationarity)}\\
C=\alpha_i+\mu_i &amp;\text{(stationarity)}\\
0=\alpha_i(y_i f(\boldsymbol x_i)-1+\xi_i) &amp;\text{(complementary)}\\
0=\mu_i\xi_i &amp;\text{(complementary)}\\
y_i f(\boldsymbol x_i)-1+\xi_i \ge 0 &amp;\text{(primal feasibility)}\\
\xi_i \ge 0 &amp;\text{(primal feasibility)}\\
\alpha_i \ge 0 &amp;\text{(dual feasibility)}\\
\mu_i \ge 0 &amp;\text{(dual feasibility)}\\
\end{cases}\,.\]

<p>Thus, we have</p>

\[\begin{cases}
y_i f(\boldsymbol x_i) \ge 1 &amp;(\alpha_i=0)\\
y_i f(\boldsymbol x_i) \le 1 &amp;(\alpha_i=C)\\
y_i f(\boldsymbol x_i) = 1 &amp;(\text{otherwise})\\
\end{cases}\,.\tag{2}\]

<p>When $S=\{j \mid 0 &lt; \alpha_j &lt; C\} \neq \varnothing$, for each such $j$,</p>

\[\begin{aligned}
y_j (\boldsymbol w^\top\phi(\boldsymbol x_j)+b) &amp;= 1\\
b &amp;= y_j - \boldsymbol w^\top\phi(\boldsymbol x_j)\,;\\
\end{aligned}\]

<p>The second equality holds since $y_j = \pm 1$.
For numerical stability, we take the mean of all $b$’s as the final value of the intercept:</p>

\[b = \frac{1}{\\|S\\|}\sum_{j \in S} (y_j-\boldsymbol w^\top\phi(\boldsymbol x_j))\,.\]

<p>When $S=\varnothing$, taking the first two cases of Equation $(2)$, it follows that</p>

\[\begin{cases}
f(\boldsymbol x_i) \ge 1 &amp;(\alpha_i=0,y_i=1)\\
f(\boldsymbol x_i) \le -1 &amp;(\alpha_i=0,y_i=-1)\\
f(\boldsymbol x_i) \le 1 &amp;(\alpha_i=C,y_i=1)\\
f(\boldsymbol x_i) \ge -1 &amp;(\alpha_i=C,y_i=-1)\\
\end{cases}\,.\]

<p>Equivalently, we have</p>

\[\max_{j \in T_1}\{y_j - \boldsymbol w^\top\phi(\boldsymbol x_j)\} \le b \le \min_{j \in T_2}\{y_j - \boldsymbol w^\top\phi(\boldsymbol x_j)\}\,,\]

<p>where</p>

\[\begin{cases}
T_1 = \{j \mid \alpha_j=0,y_j=1\text{ or }\alpha_j=C,y_j=-1\}\\
T_2 = \{j \mid \alpha_j=0,y_j=-1\text{ or }\alpha_j=C,y_j=1\}\\
\end{cases}\,,\]

<p>The intercept is taken as the mean of the lower and upper bounds.</p>

<p>To compute $\boldsymbol w^\top\phi(\boldsymbol x)$ in above equations, simply plug in $\boldsymbol w=\sum_{i=1}^m\alpha_i y_i \phi(\boldsymbol x_i)$ and compute the $\phi(\boldsymbol x_i)^\top\phi(\boldsymbol x)$ with the underlying kernel function $\kappa(\boldsymbol x_i,\boldsymbol x)$.</p>

<h2 id="compute-the-intercept-in-dual-formulation">Compute the intercept in dual formulation</h2>

<blockquote>
  <p>Reference: Chih-Chung Chang and Chih-Jen Lin. Libsvm: a library for support vector machines. ACM transactions on intelligent systems and technology (TIST), 2(3):1–27, 2011.</p>
</blockquote>

<p>The dual SVM problem is:</p>

\[\min_{\boldsymbol\alpha}\frac{1}{2}\sum_{i=1}^m\sum_{j=1}^m\alpha_i\alpha_j y_i y_j \phi(\boldsymbol x_i)^\top\phi(\boldsymbol x_j)-\sum_{i=1}^m\alpha_i\,;\quad\text{s.t. }\sum_{i=1}^m\alpha_i y_i=0,\ 0 \le \alpha_i \le C\,.\tag{3}\]

<p>The Lagrangian is:</p>

\[\hat L(\boldsymbol\alpha,\beta,\boldsymbol\lambda,\boldsymbol\nu) = \frac{1}{2}\boldsymbol\alpha^\top\mathbf Q\boldsymbol\alpha - \boldsymbol\alpha^\top\mathbf 1+\beta\boldsymbol\alpha^\top\boldsymbol y-\boldsymbol\alpha^\top\boldsymbol\lambda+(\boldsymbol\alpha-C\mathbf 1)^\top\boldsymbol\nu\,,\tag{4}\]

<p>where $\lambda_i \ge 0$, $\nu_i \ge 0$, $\mathbf 1$ is an all-$1$ vector, $\mathbf Q$ is an $m \times m$ matrix such that $Q_{ij} = y_i\phi(\boldsymbol x_i)^\top\phi(\boldsymbol x_j)y_j$, and $\beta$ is actually the intercept.
We’ll assume it for now, and reveal why it is in the end.
The KKT conditions are:</p>

\[\begin{cases}
\mathbf Q\boldsymbol\alpha=1-\beta\boldsymbol y+\boldsymbol\lambda-\boldsymbol\nu &amp;\text{(stationarity)}\\
\lambda_i\alpha_i = 0 &amp;\text{(complementary)}\\
\nu_i(C-\alpha_i) = 0 &amp;\text{(complementary)}\\
\boldsymbol\alpha^\top\boldsymbol y = 0 &amp;\text{(primal feasibility)}\\
0 \le \alpha_i \le C &amp;\text{(primal feasibility)}\\
\lambda_i \ge 0 &amp;\text{(dual feasibility)}\\
\nu_i \ge 0 &amp;\text{(dual feasibility)}\\
\end{cases}\,.\tag{5}\]

<p>Thus, we have</p>

\[\begin{cases}
(\mathbf Q\boldsymbol\alpha)_i \ge 1 - \beta y_i &amp;(\alpha_i=0)\\
(\mathbf Q\boldsymbol\alpha)_i \le 1 - \beta y_i &amp;(\alpha_i=C)\\
(\mathbf Q\boldsymbol\alpha)_i = 1 - \beta y_i &amp;(\text{otherwise})\\
\end{cases}\,.\tag{6}\]

<p>where $(\mathbf Q\boldsymbol\alpha)_i$ is the $i$th element of the vector $\mathbf Q\boldsymbol\alpha$.
When $S=\{j \mid 0 &lt; \alpha_j &lt; C\} \neq \varnothing$, for each such $j$,</p>

\[\beta = y_j(1 - (\mathbf Q\boldsymbol\alpha)_j)\,;\]

<p>which holds since $y_j = \pm 1$.
For numerical stability, we take the mean of all $\beta$’s as the final value of the intercept:</p>

\[\beta = \frac{1}{\\|S\\|}\sum_{j \in S} y_j (1 - (\mathbf Q\boldsymbol\alpha)_j)\,.\]

<p>When $S=\varnothing$, taking the first two cases of Equation $(6)$, it follows that</p>

\[\begin{cases}
\beta \ge 1-(\mathbf Q\boldsymbol\alpha)_i &amp;(\alpha_i=0,y_i=1)\\
\beta \le -(1-(\mathbf Q\boldsymbol\alpha)_i) &amp;(\alpha_i=0,y_i=-1)\\
\beta \le 1-(\mathbf Q\boldsymbol\alpha)_i &amp;(\alpha_i=C,y_i=1)\\
\beta \ge -(1-(\mathbf Q\boldsymbol\alpha)_i) &amp;(\alpha_i=C,y_i=-1)\\
\end{cases}\,.\]

<p>Equivalently, we have</p>

\[\max_{j \in T_1}\{y_j(1-(\mathbf Q\boldsymbol\alpha)_j)\} \le \beta \le \min_{j \in T_2}\{y_j(1-(\mathbf Q\boldsymbol\alpha)_j)\}\,,\]

<p>where</p>

\[\begin{cases}
T_1 = \{j \mid \alpha_j=0,y_j=1\text{ or }\alpha_j=C,y_j=-1\}\\
T_2 = \{j \mid \alpha_j=0,y_j=-1\text{ or }\alpha_j=C,y_j=1\}\\
\end{cases}\,,\]

<p>The intercept is taken as the mean of the lower and upper bounds.</p>

<h3 id="beta-is-the-intercept">$\beta$ is the intercept</h3>

<p>To show that $\beta$ is in fact the intercept in primal problem, we go further from Equation $(4)$, plugging in the stationarity conditions of Equation $(5)$, and it follows that</p>

\[\hat L(\boldsymbol\alpha,\beta,\boldsymbol\lambda,\boldsymbol\nu) = -\frac{1}{2}\boldsymbol\alpha^\top\mathbf Q\boldsymbol\alpha-C\mathbf 1^\top\boldsymbol\nu\,,\]

<p>where</p>

\[\boldsymbol\alpha=\mathbf Q^{-1}(1-\beta\boldsymbol y+\boldsymbol\lambda-\boldsymbol\nu)\,.\]

<p>assuming the inverse of $\mathbf Q$ exists.
Due to the structure of $\mathbf Q$, there exists a unique matrix $\mathbf Q^\frac{1}{2}$:</p>

\[Q^\frac{1}{2} =
\begin{pmatrix}
y_1\phi(\boldsymbol x_1) &amp; \dots &amp; y_m\phi(\boldsymbol x_m)\\
\end{pmatrix}\]

<p>such that $\mathbf Q=(\mathbf Q^\frac{1}{2})^\top\mathbf Q^\frac{1}{2}$.
Let $\boldsymbol w \triangleq \mathbf Q^{-\frac{1}{2}}(1-\beta\boldsymbol y+\boldsymbol\lambda-\boldsymbol\nu)=\mathbf Q^\frac{1}{2}\boldsymbol\alpha$.
The stationarity condition of Equation $(5)$ can be rewritten as:</p>

\[\begin{aligned}
\mathbf Q\boldsymbol\alpha &amp;= 1-\beta\boldsymbol y+\boldsymbol\lambda-\boldsymbol\nu\\
(\mathbf Q^\frac{1}{2})^\top\boldsymbol w &amp;= 1-\beta\boldsymbol y+\boldsymbol\lambda-\boldsymbol\nu\\
y_i\phi(\boldsymbol x_i)^\top\boldsymbol w+\beta y_i &amp;\ge 1-\nu_i\quad\forall 1 \le i \le m\\
y_i(\phi(\boldsymbol x_i)^\top\boldsymbol w+\beta) &amp;\ge 1-\nu_i\\
\end{aligned}\]

<p>Therefore, we have the dual of the dual problem as:</p>

\[\max_{\boldsymbol w,\beta,\boldsymbol\nu}-\frac{1}{2}\boldsymbol w^\top\boldsymbol w-C\mathbf 1^\top\boldsymbol\nu\,;\quad\text{s.t. }y_i(\phi(\boldsymbol x_i)^\top\boldsymbol w+\beta) \ge 1-\nu_i,\ \nu_i \ge 0\,.\]

<p>Clearly, $\beta$ is the intercept, and $\nu_i$ is the slack variable $\xi_i$ bounded to each sample in the dataset.</p>

<h2 id="show-that-the-two-apporaches-are-equivalent">Show that the two apporaches are equivalent</h2>

<p>Recall that in primal and dual formulations,</p>

\[\begin{aligned}
b &amp;= y_j - \sum_{i=1}^m\alpha_i y_i \phi(\boldsymbol x_i)^\top\phi(\boldsymbol x_j) &amp;\text{(primal formulation)}\\
b &amp;= y_j (1-(\mathbf Q\boldsymbol\alpha)_j) &amp;\text{(dual formulation)}\\
\end{aligned}\]

<p>If we plug in the definitions of $\boldsymbol w$ and $\mathbf Q$, it follows that</p>

\[\begin{aligned}
b &amp;= y_j - \sum_{i=1}^m \alpha_i y_i \phi(\boldsymbol x_i)^\top\phi(\boldsymbol x_j)\\
b &amp;= y_j (1 - y_j\sum_{i=1}^m \alpha_i y_i \phi(\boldsymbol x_i)^\top\phi(\boldsymbol x_j))\\
\end{aligned}\]

<p>But $y_j^2=1$.
Therefore, it can be easily shown that the two equations are the same.</p>

<h2 id="verify-the-conclusion-by-experiment">Verify the conclusion by experiment</h2>

<p>We will need <a href="https://numpy.org/"><code class="language-plaintext highlighter-rouge">numpy</code></a> and <a href="https://scikit-learn.org/stable/"><code class="language-plaintext highlighter-rouge">scikit-learn</code></a> to perform the experiment.</p>

<p>Get to know <code class="language-plaintext highlighter-rouge">SVC</code> class in <code class="language-plaintext highlighter-rouge">scikit-learn</code> <a href="https://scikit-learn.org/stable/modules/svm.html#svc">here</a>.
In summary, given a classifier <code class="language-plaintext highlighter-rouge">clf = SVC(...).fit(X, y)</code>,</p>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">clf.dual_coef_</code> holds the product $y_i \alpha_i$ for each $\alpha_i &gt; 0$;</li>
  <li>
<code class="language-plaintext highlighter-rouge">clf.support_vector_</code> holds the support vectors of shape <code class="language-plaintext highlighter-rouge">(n_SV, n_feature)</code> where <code class="language-plaintext highlighter-rouge">n_SV</code> is the number of support vectors;</li>
  <li>
<code class="language-plaintext highlighter-rouge">clf.intercept_</code> holds the intercept term.</li>
</ul>

<p>In addition,</p>

<ul>
  <li>
<code class="language-plaintext highlighter-rouge">clf.coef_</code> holds the $\boldsymbol w$ in primal problem. We will use it for convenience below (linear kernel).</li>
</ul>

<p>Codes:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>


<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1"># Restrict the classification problem to two-class;
# otherwise, the problem will become unnecessarily complex.
</span><span class="n">i</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">|</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="c1"># Make y take values {0, 1} rather than {0, 2}.
</span><span class="n">y</span> <span class="o">//=</span> <span class="mi">2</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'linear'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># The y for support vectors.
# The `*2-1` operation is used to make it pick the values {1, -1}
# rather than {1, 0}.
</span><span class="n">y_supp</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">clf</span><span class="p">.</span><span class="n">support_</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="c1"># The filter that removes upper bounded alpha's.
</span><span class="n">S</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">dual_coef_</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">1</span>

<span class="c1"># Verify that the `clf.coef_` is indeed computed from `clf.dual_coef_`.
# We'll use `clf.coef_` for convenience below.
</span><span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span>
    <span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">coef_</span><span class="p">),</span>
    <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">dual_coef_</span><span class="p">)</span> <span class="o">*</span> <span class="n">clf</span><span class="p">.</span><span class="n">support_vectors_</span><span class="p">.</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="c1"># The intercept estimations in primal formulation. Only support vectors are
# required, since otherwise the dual coefficients will be zero and won't count
# any.
</span><span class="n">b_estimates_primal</span> <span class="o">=</span> <span class="n">y_supp</span><span class="p">[</span><span class="n">S</span><span class="p">]</span> <span class="o">-</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">support_vectors_</span><span class="p">[</span><span class="n">S</span><span class="p">],</span> <span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="c1">### Verify that the mean of the estimations is indeed the intercept. ###
</span><span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b_estimates_primal</span><span class="p">),</span> <span class="n">clf</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="c1"># The kernel matrix.
</span><span class="n">K</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">support_vectors_</span><span class="p">,</span> <span class="n">clf</span><span class="p">.</span><span class="n">support_vectors_</span><span class="p">.</span><span class="n">T</span><span class="p">)</span>
<span class="c1"># The Q matrix times alpha. Notice that when computing Q, only support vectors
# are required for the same reason as above.
</span><span class="n">Q_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">dual_coef_</span><span class="p">)[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="o">*</span> <span class="n">K</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="n">y_supp</span>
<span class="c1"># The intercept estimations in dual formulation.
</span><span class="n">b_estimates_dual</span> <span class="o">=</span> <span class="n">y_supp</span><span class="p">[</span><span class="n">S</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Q_alpha</span><span class="p">[</span><span class="n">S</span><span class="p">])</span>
<span class="c1">### Verify that the mean of the estimations is indeed the intercept. ###
</span><span class="k">assert</span> <span class="n">np</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">clf</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">b_estimates_dual</span><span class="p">))</span>
</code></pre></div></div>

<p>The following has been mentioned in the comment above, but I feel it necessary to redeclare them formally here:
Recall that $\boldsymbol w = \sum_{i=1}^m\alpha_i y_i \phi(\boldsymbol x_i)$, and all $m$ $\alpha$’s are involved when computing $\mathbf Q\boldsymbol\alpha$.
In fact, only those $i$ such that $\alpha_i &gt; 0$ (corresponding to the support vectors) are necessary.
That’s why we are able to find $\boldsymbol w$ and $\mathbf Q\boldsymbol\alpha$ even if <code class="language-plaintext highlighter-rouge">scikit-learn</code> stores only data related to support vectors.</p>

<p><em>Caveat</em>:
I find it quite hard to construct an example where there’s no free $\alpha$’s (i.e. those $\alpha_i$ such that $0 &lt; \alpha_i &lt; C$) at all.
So strictly speaking, such edge case is not verified empirically in this post.</p>

  </div>
<a class="u-url" href="/2023/08/05/compute-svm-intercept.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Kaiwen's personal website</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Kaiwen's personal website</li>
<li><a class="u-email" href="mailto:kps6326@hotmail.com">kps6326@hotmail.com</a></li>
</ul>
      </div>

      <div class="footer-col footer-col-2">
<ul class="social-media-list"><li><a href="https://github.com/kkew3"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">kkew3</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>My blogs and research reports.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
