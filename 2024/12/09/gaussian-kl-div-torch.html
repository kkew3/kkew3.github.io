<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>KL divergence between two full-rank Gaussians in PyTorch | Kaiwen’s personal website</title>
<meta name="generator" content="Jekyll v3.10.0">
<meta property="og:title" content="KL divergence between two full-rank Gaussians in PyTorch">
<meta property="og:locale" content="en_US">
<meta name="description" content="Abstract">
<meta property="og:description" content="Abstract">
<link rel="canonical" href="https://kkew3.github.io/2024/12/09/gaussian-kl-div-torch.html">
<meta property="og:url" content="https://kkew3.github.io/2024/12/09/gaussian-kl-div-torch.html">
<meta property="og:site_name" content="Kaiwen’s personal website">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2024-12-09T08:03:00+00:00">
<meta name="twitter:card" content="summary">
<meta property="twitter:title" content="KL divergence between two full-rank Gaussians in PyTorch">
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-12-09T08:03:00+00:00","datePublished":"2024-12-09T08:03:00+00:00","description":"Abstract","headline":"KL divergence between two full-rank Gaussians in PyTorch","mainEntityOfPage":{"@type":"WebPage","@id":"https://kkew3.github.io/2024/12/09/gaussian-kl-div-torch.html"},"url":"https://kkew3.github.io/2024/12/09/gaussian-kl-div-torch.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css">
<link type="application/atom+xml" rel="alternate" href="https://kkew3.github.io/feed.xml" title="Kaiwen's personal website">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2YQN8LEHLR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-2YQN8LEHLR');
</script>
<script>MathJax={"tex":{"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"svg":{"fontCache":"global"}}</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
<header class="site-header" role="banner">

  <div class="wrapper">
<a class="site-title" rel="author" href="/">Kaiwen's personal website</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger">
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewbox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"></path>
            </svg>
          </span>
        </label>

        <div class="trigger">
<a class="page-link" href="/tags/">Tags</a><a class="page-link" href="/docs/">Docs</a><a class="page-link" href="/about/">About</a>
</div>
      </nav>
</div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">KL divergence between two full-rank Gaussians in PyTorch</h1>
    <span><a href="https://kkew3.github.io/tags/math--prob"><code class="highlighter-rouge"><nobr>math/probability</nobr></code></a> | <a href="https://kkew3.github.io/tags/dev--pytorch"><code class="highlighter-rouge"><nobr>dev/pytorch</nobr></code></a></span>
    <p class="post-meta">
      <time class="dt-published" datetime="2024-12-09T08:03:00+00:00" itemprop="datePublished">Dec 9, 2024 at 08:03:00
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="abstract">Abstract</h2>

<p>In this post, we will go through the <a href="https://pytorch.org/">PyTorch</a> code to compute the Kullback-Leibler divergence between two full-rank Gaussians.
The code might be useful if one considers using full-rank Gaussian as variational posterior while training a <a href="https://arxiv.org/abs/1312.6114">variational autoencoder</a>.</p>

<h2 id="kl-divergence-between-two-full-rank-gaussians">KL divergence between two full-rank Gaussians</h2>

<p>It’s common practice to parameterize the covariance matrix $\boldsymbol\Sigma$ of a $d$-dimensional full-rank Gaussian using a $D$-dimensional vector of nonzero elements of $\mathbf L$, where $D = d(1+d)/2$ and $\boldsymbol\Sigma = \mathbf L \mathbf L^\top$ is the Cholesky decomposition.
So we will assume it here.
Note that the diagonal of $\mathbf L$ must be positive so that $\boldsymbol\Sigma$ is positive definite.
We will enforce this by taking the exponential on the diagonal elements (e.g. the first $d$ elements of our parameterization).</p>

<p>Let the two Gaussians be $p(\boldsymbol x) = \mathcal N(\boldsymbol x \mid \boldsymbol\mu_1, \boldsymbol\Sigma_1)$ and $q(\boldsymbol x) = \mathcal N(\boldsymbol x \mid \boldsymbol\mu_2, \boldsymbol\Sigma_2)$.
Per <a href="https://statproofbook.github.io/P/mvn-kl">The Book of Statistical Proofs</a>, the KL divergence between them is:</p>

\[D_\mathrm{KL}(p \parallel q) = \frac{1}{2}\left((\boldsymbol\mu_2 - \boldsymbol\mu_1)^\top \boldsymbol\Sigma_2^{-1} (\boldsymbol\mu_2 - \boldsymbol\mu_1) + \operatorname{tr}(\boldsymbol\Sigma_2^{-1} \boldsymbol\Sigma_1) - \log \frac{\det \boldsymbol\Sigma_1}{\det \boldsymbol\Sigma_2} - d\right)\,.\]

<p>Plugging in our parameterization of the covariance matrices:</p>

\[\begin{aligned}
    D_\mathrm{KL}(p \parallel q)
    &amp;= \frac{1}{2}\left((\boldsymbol\mu_2 - \boldsymbol\mu_1)^\top \mathbf L_2^{-\top} \mathbf L_2^{-1} (\boldsymbol\mu_2 - \boldsymbol\mu_1) + \operatorname{tr}((\mathbf L_2 \mathbf L_2^\top)^{-1} (\mathbf L_1 \mathbf L_1^\top)) - \log \frac{\det(\mathbf L_1 \mathbf L_1^\top)}{\det(\mathbf L_2 \mathbf L_2^\top)} - d\right)\\
    &amp;= \frac{1}{2}\left((\mathbf L_2^{-1} (\boldsymbol\mu_2 - \boldsymbol\mu_1))^\top (\mathbf L_2^{-1} (\boldsymbol\mu_2 - \boldsymbol\mu_1)) + \operatorname{tr}((\mathbf L_2^{-1} \mathbf L_1)^\top (\mathbf L_2^{-1} \mathbf L_1)) - 2\log\frac{\det\mathbf L_1}{\det\mathbf L_2} - d\right)\,.\\
\end{aligned}\]

<p>We have used the following facts:</p>

<ul>
  <li>the <a href="https://en.wikipedia.org/wiki/Trace_(linear_algebra)#Cyclic_property">cyclic property of trace</a>;</li>
  <li>$\det \mathbf A = \det \mathbf A^\top$;</li>
  <li>$\log\det (\mathbf A \mathbf B) = \log\det(\mathbf A) + \log\det(\mathbf B)$.</li>
</ul>

<p>It follows that:</p>

\[D_\mathrm{KL}(p \parallel q) = \frac{1}{2}\big(\boldsymbol y^\top \boldsymbol y + \|\mathbf M\|_F^2 - 2 (\operatorname{tr}(\log \mathbf L_1) - \operatorname{tr}(\log \mathbf L_2)) - d\big)\,,\]

<p>where $\mathbf L_2 \boldsymbol y = \boldsymbol\mu_2 - \boldsymbol\mu_1$, and $\mathbf L_2 \mathbf M = \mathbf L_1$.</p>

<p>We have denoted:</p>

<ul>
  <li>$\|\cdot\|_F$ as the Frobenius norm of a matrix;</li>
  <li>$\log \mathbf A$ as the elementwise logarithm of $\mathbf A$.</li>
</ul>

<p>We have used the following facts:</p>

<ul>
  <li>$\operatorname{tr}(\mathbf A^\top \mathbf A) = \|\mathbf A\|_F^2$;</li>
  <li>$\log\det \mathbf L = \operatorname{tr}(\log \mathbf L)$ when $\mathbf L$ is a lower triangular matrix.</li>
</ul>

<h3 id="code">Code</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">distributions</span> <span class="k">as</span> <span class="n">D</span>


<span class="k">def</span> <span class="nf">form_cholesky_tril_from_elements</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">scale_tril_elems</span><span class="p">):</span>
    <span class="s">"""
    Form the Cholesky lower triangular matrix from its elements.

    Args:
        d (int): The number of rows/columns in the square matrix.
        scale_tril_elems (torch.Tensor): The Cholesky lower triangular
            elements, of shape (batch_size, (1 + d) * d // 2).

    Returns:
        torch.Tensor: A tensor of shape (batch_size, d, d).
    """</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">scale_tril_elems</span><span class="p">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">scale_tril_elems</span><span class="p">.</span><span class="n">device</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tril_indices</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">l_mat</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">l_mat</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">scale_tril_elems</span>
    <span class="n">l_mat_diag</span> <span class="o">=</span> <span class="n">l_mat</span><span class="p">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">l_mat_diag</span><span class="p">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">l_mat_diag</span><span class="p">.</span><span class="n">exp</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">l_mat</span>


<span class="n">d</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">5</span>


<span class="k">def</span> <span class="nf">groundtruth</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">scale_tril1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">scale_tril2</span><span class="p">):</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">D</span><span class="p">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mean1</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale_tril1</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">=</span> <span class="n">D</span><span class="p">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mean2</span><span class="p">,</span> <span class="n">scale_tril</span><span class="o">=</span><span class="n">scale_tril2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">D</span><span class="p">.</span><span class="n">kl_divergence</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">ours</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">scale_tril1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">scale_tril2</span><span class="p">):</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">solve_triangular</span><span class="p">(</span>
        <span class="n">scale_tril2</span><span class="p">,</span> <span class="p">(</span><span class="n">mean2</span> <span class="o">-</span> <span class="n">mean1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">upper</span><span class="o">=</span><span class="bp">False</span><span class="p">).</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">y2</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="n">square</span><span class="p">().</span><span class="nb">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">solve_triangular</span><span class="p">(</span><span class="n">scale_tril2</span><span class="p">,</span> <span class="n">scale_tril1</span><span class="p">,</span> <span class="n">upper</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">M2</span> <span class="o">=</span> <span class="n">M</span><span class="p">.</span><span class="n">square</span><span class="p">().</span><span class="n">flatten</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="nb">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">y2</span> <span class="o">+</span> <span class="n">M2</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">scale_tril1</span><span class="p">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">log</span><span class="p">().</span><span class="nb">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="o">-</span> <span class="n">scale_tril2</span><span class="p">.</span><span class="n">diagonal</span><span class="p">(</span><span class="n">dim1</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="o">=-</span><span class="mi">1</span><span class="p">).</span><span class="n">log</span><span class="p">().</span><span class="nb">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span> <span class="o">-</span> <span class="n">d</span><span class="p">)</span>


<span class="c1"># Randomize p and q's parameterization.
</span><span class="n">mean1</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
<span class="n">mean2</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span>
<span class="n">scale_tril1</span> <span class="o">=</span> <span class="n">form_cholesky_tril_from_elements</span><span class="p">(</span>
    <span class="n">d</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">scale_tril2</span> <span class="o">=</span> <span class="n">form_cholesky_tril_from_elements</span><span class="p">(</span>
    <span class="n">d</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">d</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span> <span class="o">//</span> <span class="mi">2</span><span class="p">))</span>

<span class="c1"># Assert the correctness.
</span><span class="k">assert</span> <span class="n">torch</span><span class="p">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">groundtruth</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">scale_tril1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">scale_tril2</span><span class="p">),</span>
                      <span class="n">ours</span><span class="p">(</span><span class="n">mean1</span><span class="p">,</span> <span class="n">scale_tril1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">,</span> <span class="n">scale_tril2</span><span class="p">))</span>
</code></pre></div></div>

<p>Profile our implementation:</p>

<p><code class="language-plaintext highlighter-rouge">%timeit groundtruth(mean1, scale_tril1, mean2, scale_tril2)</code> (baseline):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>164 μs ± 178 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">%timeit ours(mean1, scale_tril1, mean2, scale_tril2)</code> (our implementation):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>46.2 μs ± 71.6 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)
</code></pre></div></div>

  </div>
<a class="u-url" href="/2024/12/09/gaussian-kl-div-torch.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Kaiwen's personal website</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Kaiwen's personal website</li>
<li><a class="u-email" href="mailto:kps6326@hotmail.com">kps6326@hotmail.com</a></li>
</ul>
      </div>

      <div class="footer-col footer-col-2">
<ul class="social-media-list"><li><a href="https://github.com/kkew3"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">kkew3</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>My blogs and research reports.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
